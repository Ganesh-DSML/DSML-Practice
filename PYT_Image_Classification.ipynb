{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQoBybrjyd417F/TzsIhjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ganesh-DSML/DSML-Practice/blob/main/PYT_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. Download images from the internet"
      ],
      "metadata": {
        "id": "dzFtfd81K887"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kDJGNBXeJwpm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_images(image_urls, save_dir, prefix = 'IMG_'):\n",
        "  os.makedirs(save_dir, exist_ok=True)\n",
        "  for i, url in enumerate(image_urls):\n",
        "    try:\n",
        "      resp = requests.get(url, timeout=10)\n",
        "      resp.raise_for_status()\n",
        "      img = Image.open(BytesIO(resp.content)).convert(\"RGB\")\n",
        "      fname = os.path.join(save_dir, f'{prefix}_{i}.jpg')\n",
        "      img.save(fname)\n",
        "    except Exception as e:\n",
        "      print(f'Error downloading image {url} : {e}')"
      ],
      "metadata": {
        "id": "SkYEThizLObO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_urls = [\n",
        "    'https://stimg.cardekho.com/images/carexteriorimages/630x420/Jaguar/F-Pace/10644/1755774688332/front-left-side-47.jpg?impolicy=resize&imwidth=480',\n",
        "    'https://img.autocarindia.com/ExtraImages/20241205062334_20240606032223_Creta%20showroom%20shot%20_1_.jpg',\n",
        "    'https://cdni.autocarindia.com/Features/_New%20Sedans%20%20Sports%20Cars%20Web%20Resized%20%20Watermarked._008.jpeg',\n",
        "    'https://a.storyblok.com/f/197805/7a2484c876/how-to-create-a-car-newblogcover.png',\n",
        "    'https://kidsroar.in/cdn/shop/files/8989898_ff5f50c0-0de9-45c8-b9fb-61c8aa0ef070_800x.jpg?v=1692355576'\n",
        "            ]\n",
        "\n",
        "truck_urls = [\n",
        "    'https://www.tatamotors.com/wp-content/uploads/2023/10/press-13sep23-01.jpg',\n",
        "    'https://plus.unsplash.com/premium_photo-1664695368767-c42483a0bda1?fm=jpg&q=60&w=3000&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MXx8dHJ1Y2t8ZW58MHx8MHx8fDA%3D',\n",
        "    'https://www.macktrucks.com/trucks/media_1818f3d88d2375704ad949bbd5f4d34ec2039895f.png?width=750&format=png&optimize=medium',\n",
        "    'https://5.imimg.com/data5/MW/JN/FM/SELLER-89031277/10-chakka-for-sale-in-indore-1000x1000.png',\n",
        "    'https://fordtrucksglobal.com/Uploads/Page/technologies_05.jpg'\n",
        " ]\n",
        "ute_urls = [\n",
        "    'https://www.chevrolet.com/content/dam/chevrolet/na/us/english/vdc-collections/2025/trucks/colorado/nav/2025-colorado-4zr-gal-driver-front-3quarter-nav.jpg?imwidth=960',\n",
        "    'https://imgd.aeplcdn.com/1280x720/n/cw/ec/191395/kia-left-front-three-quarter1.jpeg?isig=0',\n",
        "    'https://autoimage.capitalone.com/cms/Auto/assets/images/3403-hero-2024-chevrolet-silverado-hd-zr2.jpg',\n",
        "    'https://www.topgear.com/sites/default/files/news-listicle/image/2023/11/TRUCKSLEAD.jpg',\n",
        "    'https://static01.nytimes.com/newsgraphics/2023-02-14-big-evs/a09067a7b772d4328be9141db7df9f91b33c0e04/_assets/cars-rivian-rivian.jpg'\n",
        "]\n",
        "\n",
        "download_images(car_urls, 'data/cars', prefix = 'CAR')\n",
        "download_images(truck_urls, 'data/trucks', prefix = 'TRUCK')\n",
        "download_images(ute_urls, 'data/utes', prefix = 'UTE')"
      ],
      "metadata": {
        "id": "GCPqRS_dOtIh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2. Imports & transforms (image preprocessing / augmentation)"
      ],
      "metadata": {
        "id": "IdsyLQd5PvbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "yD2X6fepO-Ga"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
        "])"
      ],
      "metadata": {
        "id": "wVGaKGH6QNwk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3. Build ImageFolder + stratified train/val split"
      ],
      "metadata": {
        "id": "mfoYmmlIzSwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = 'data'\n",
        "data_for_split = datasets.ImageFolder(root =data_directory)\n",
        "indices = list(range(len(data_for_split)))\n",
        "labels = [s[1] for s in data_for_split.samples]\n",
        "train_indices, val_indices = train_test_split(indices, test_size=0.2, stratify = labels, random_state=42)\n",
        "train_dataset_full = datasets.ImageFolder(root = data_directory, transform = train_transform)\n",
        "val_dataset_full = datasets.ImageFolder(root = data_directory, transform = val_transform)\n",
        "train_dataset = Subset(train_dataset_full, train_indices)\n",
        "val_dataset = Subset(val_dataset_full, val_indices)"
      ],
      "metadata": {
        "id": "Z_hKjIYYRkqH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total Images: {len(data_for_split)}')\n",
        "print(f'Train Images: {len(train_dataset)}')\n",
        "print(f'Validation Images: {len(val_dataset)}')\n",
        "print(f'Class Names: {data_for_split.classes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgPkjIiYRjUD",
        "outputId": "d83f4b95-e1c7-44eb-af54-2372bd00027a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Images: 15\n",
            "Train Images: 12\n",
            "Validation Images: 3\n",
            "Class Names: ['cars', 'trucks', 'utes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4. DataLoaders (batches, shuffling, prefetch)"
      ],
      "metadata": {
        "id": "kdjhYtlszKDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_workers =  2\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = False, num_workers=num_workers, pin_memory=True)"
      ],
      "metadata": {
        "id": "SxG5fJlOSC9Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5. Build the model (transfer learning with ResNet18)"
      ],
      "metadata": {
        "id": "RTB9QgeWzY5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = models.resnet18(pretrained = True)\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "num_classes = len(data_for_split.classes)\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ5cR98-y4dC",
        "outputId": "73242e8b-e762-423a-bb8a-303d7e2032ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 135MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6. Loss, optimizer, and (optional) learning rate scheduler"
      ],
      "metadata": {
        "id": "3NHyFOxd0YEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr = 1e-3)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "fvkskb7K0UKc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7. Training & validation loop"
      ],
      "metadata": {
        "id": "CAyAfizs3YBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_1_epoch(model, dataloader, criterion, optimizer, device):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "\n",
        "  for inputs, labels in dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item() *inputs.size(0)\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "  epoch_loss = running_loss / len(dataloader.dataset)\n",
        "  epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "  return epoch_loss, epoch_acc.item()"
      ],
      "metadata": {
        "id": "_V_l2GWQ05wP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "\n",
        "  all_preds = []\n",
        "  all_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      running_loss += loss.item()*inputs.size(0)\n",
        "      running_corrects += torch.sum(preds==labels.data)\n",
        "\n",
        "      all_preds.extend(preds.cpu().numpy())\n",
        "      all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "  epoch_loss = running_loss / len(dataloader.dataset)\n",
        "  epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "  return epoch_loss, epoch_acc.item(), np.array(all_labels), np.array(all_preds)"
      ],
      "metadata": {
        "id": "SbX6yudK5QVL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Loop\n",
        "num_epochs = 5\n",
        "best_val_acc = 0.0\n",
        "best_model_wts = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  since = time.time()\n",
        "  train_loss, train_acc = train_1_epoch(model, train_loader, criterion, optimizer, device)\n",
        "  val_loss, val_acc, val_labels, val_preds = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  if val_acc > best_val_acc:\n",
        "    best_val_acc = val_acc\n",
        "    best_model_wts = model.state_dict()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "          f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f} - \"\n",
        "          f\"Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f} - \"\n",
        "          f\"time: {time.time()-since:.1f}s\")\n",
        "\n",
        "if best_model_wts is not None:\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  torch.save(best_model_wts, 'best_model.pth')\n",
        "  print('Save best_model.pth with val acc:', best_val_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEKgBqcB7AeV",
        "outputId": "5b22812c-7406-4418-e342-85b2f8931eab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train loss: 1.2129, Train acc: 0.2500 - Val loss: 1.0685, Val acc: 0.3333 - time: 2.3s\n",
            "Epoch 2/5 - Train loss: 1.0804, Train acc: 0.4167 - Val loss: 1.0213, Val acc: 0.3333 - time: 2.5s\n",
            "Epoch 3/5 - Train loss: 1.0382, Train acc: 0.5000 - Val loss: 0.9742, Val acc: 0.6667 - time: 3.1s\n",
            "Epoch 4/5 - Train loss: 0.8948, Train acc: 0.7500 - Val loss: 0.9303, Val acc: 0.6667 - time: 2.2s\n",
            "Epoch 5/5 - Train loss: 0.9094, Train acc: 0.6667 - Val loss: 0.8773, Val acc: 0.6667 - time: 2.2s\n",
            "Save best_model.pth with val acc: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SUBcOeFJ9fd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}